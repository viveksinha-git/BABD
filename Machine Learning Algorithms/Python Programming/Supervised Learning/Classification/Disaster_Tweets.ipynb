{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis deals with twitter data to predict whether a given tweet really talks about a particular disaster, or just a fake tweet. The kaggle competition link is: https://www.kaggle.com/c/nlp-getting-started/overview\n",
    "\n",
    "Importing the necessary modules for the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And downloading the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\toviv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\toviv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\toviv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the `train` and `test` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "t1 = test   # keeping a copy of the test dataset\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of NULL values in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that out of 7613 observations, the `location` variable has 2533 NULL values. Hence, I decide to delete the entire column.\n",
    "\n",
    "Additionally, the `keyword` variable has 61 NULLS, hence I decided to delete all observations where `keyword` has NULL values.\n",
    "\n",
    "Thus, the dataset is now free of NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7552, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('location', axis=1, inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True) # resetting the index of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, choosing the features for the train/test split, and also keeping a copy of the `x_train` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['text']\n",
    "y = train['target']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "x_train_copy = x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for the following operations:\n",
    "\n",
    "- Tokenization: creating a Bag-of-Words for every tweet\n",
    "- Stop wrods: removing stop words and punctuation marks\n",
    "- Lemmatization: converting each token to its root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  text = text.lower()\n",
    "  word_tokens = word_tokenize(text)\n",
    "  return word_tokens\n",
    "\n",
    "def remove_words(text):\n",
    "\n",
    "  # set of stop words\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  punc=['?',':','!','.',',',';','#','@','$','-','(',')','_',\"'\"]\n",
    "  punctuations = set(punc)\n",
    "\n",
    "  filtered_sentence = []\n",
    "\n",
    "  for w in text: \n",
    "      if w not in stop_words: \n",
    "        if w not in punctuations:\n",
    "          filtered_sentence.append(w) \n",
    "\n",
    "  return filtered_sentence\n",
    "\n",
    "def lemmatize(text):\n",
    "  wordnet_lemmatizer = WordNetLemmatizer()\n",
    "  lemmatized_token = []\n",
    "  for token in text:\n",
    "    w = wordnet_lemmatizer.lemmatize(token)\n",
    "    lemmatized_token.append(w)\n",
    "  return ' '.join(lemmatized_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying these functions to the `x_train` sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.apply(tokenize)\n",
    "x_train = x_train.apply(remove_words)\n",
    "x_train = x_train.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models applied on the `x_train` dataset are:\n",
    "- CountVectorizer()\n",
    "- TfidfVectorizer()\n",
    "- N-Grams\n",
    "\n",
    "All models were run on both, preprocessed (`x_train`) and raw (`x_train_copy`) datasets\n",
    "\n",
    "### 1.a. CountVectorizer on preprocessed data `x_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "x_train_bow = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Transform X_test\n",
    "x_test_bow = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first analysis was run on multiple classifiers, to compare their results (F1 score). The CrossValidation parameter has been set to 5, to obtain an accurate value of the desired scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   61.12 % , Precision 0.530 Recall : 0.802 F1-Score :  0.638\n",
      "The confusion Matrix : \n",
      "[[1620 1837]\n",
      " [ 512 2072]]\n",
      "Time used : 12.020 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   79.51 % , Precision 0.774 Recall : 0.736 F1-Score :  0.755\n",
      "The confusion Matrix : \n",
      "[[2900  557]\n",
      " [ 681 1903]]\n",
      "Time used : 10.300 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   79.69 % , Precision 0.849 Recall : 0.639 F1-Score :  0.729\n",
      "The confusion Matrix : \n",
      "[[3164  293]\n",
      " [ 934 1650]]\n",
      "Time used : 12.650 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "LogisticRegression Accuracy  :   79.77 % , Precision 0.808 Recall : 0.692 F1-Score :  0.745\n",
      "The confusion Matrix : \n",
      "[[3032  425]\n",
      " [ 797 1787]]\n",
      "Time used : 29.282 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "names = [\"Gaussian Naive Bayes\", \"Multinomial Naive Bayes\",\"Bernoulli Naive Bayes\", \"LogisticRegression\"]\n",
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB(), LogisticRegression()]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,x_train_bow.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the Multinomial Naive Bayes Classifier provides the best F1 score among all the classifiers. Hence, I will proceed with Multinomial Naive Bayes Classifier for further analysis.\n",
    "\n",
    "Once the validation is done, I will now predict the `target` variable from the `test` dataset.\n",
    "\n",
    "The predictions are merged with the `test` dataset, the unnecessary variables are removed, and the resultant dataframe is downloaded, as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_bow.toarray(),y_train)\n",
    "\n",
    "y_test = test['text']\n",
    "y_test = y_test.apply(tokenize)\n",
    "y_test = y_test.apply(remove_words)\n",
    "y_test = y_test.apply(lemmatize)\n",
    "\n",
    "test_bow = vectorizer.transform(y_test)\n",
    "\n",
    "y_pred = clf.predict(test_bow)\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "\n",
    "test['target'] = pred\n",
    "\n",
    "test = test.drop(['keyword','location','text'], axis=1)\n",
    "\n",
    "test.to_csv('bowMNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting these predicted score resulted in a score of 0.79754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1jAQfnlr2EnpSqEB5XPjlCWCvofX_nmqX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. CountVectorizer on raw data `x_train_copy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   61.86 % , Precision 0.537 Recall : 0.796 F1-Score :  0.641\n",
      "The confusion Matrix : \n",
      "[[1681 1776]\n",
      " [ 528 2056]]\n",
      "Time used : 12.700 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   79.57 % , Precision 0.785 Recall : 0.719 F1-Score :  0.751\n",
      "The confusion Matrix : \n",
      "[[2949  508]\n",
      " [ 726 1858]]\n",
      "Time used : 10.972 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   79.79 % , Precision 0.840 Recall : 0.651 F1-Score :  0.734\n",
      "The confusion Matrix : \n",
      "[[3137  320]\n",
      " [ 901 1683]]\n",
      "Time used : 13.501 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toviv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy  :   79.84 % , Precision 0.804 Recall : 0.699 F1-Score :  0.748\n",
      "The confusion Matrix : \n",
      "[[3018  439]\n",
      " [ 779 1805]]\n",
      "Time used : 39.409 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "x_train_bow = vectorizer.fit_transform(x_train_copy)\n",
    "\n",
    "# Transform X_test\n",
    "x_test_bow = vectorizer.transform(x_test)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,x_train_bow.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the LogisticRegression Classifier due to its higher F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toviv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x_train_bow.toarray(),y_train)\n",
    "\n",
    "test = t1\n",
    "y_test = test['text']\n",
    "\n",
    "test_bow = vectorizer.transform(y_test)\n",
    "\n",
    "y_pred = clf.predict(test_bow)\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "\n",
    "test['target'] = pred\n",
    "\n",
    "test = test.drop(['keyword','location','text'], axis=1)\n",
    "\n",
    "test.to_csv('rawLR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TfidfVectorizer() on preprocessed data `x_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "x_train_tf = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   60.82 % , Precision 0.529 Recall : 0.765 F1-Score :  0.626\n",
      "The confusion Matrix : \n",
      "[[1696 1761]\n",
      " [ 606 1978]]\n",
      "Time used : 12.616 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   79.87 % , Precision 0.848 Recall : 0.646 F1-Score :  0.733\n",
      "The confusion Matrix : \n",
      "[[3157  300]\n",
      " [ 916 1668]]\n",
      "Time used : 3.422 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   79.69 % , Precision 0.849 Recall : 0.639 F1-Score :  0.729\n",
      "The confusion Matrix : \n",
      "[[3164  293]\n",
      " [ 934 1650]]\n",
      "Time used : 6.584 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "LogisticRegression Accuracy  :   79.16 % , Precision 0.852 Recall : 0.621 F1-Score :  0.718\n",
      "The confusion Matrix : \n",
      "[[3178  279]\n",
      " [ 980 1604]]\n",
      "Time used : 13.301 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "# Transform X_test\n",
    "x_test_tf = vectorizer.transform(x_test)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,x_train_tf.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_tf.toarray(),y_train)\n",
    "\n",
    "test = t1\n",
    "y_test = test['text']\n",
    "y_test = y_test.apply(tokenize)\n",
    "y_test = y_test.apply(remove_words)\n",
    "y_test = y_test.apply(lemmatize)\n",
    "\n",
    "test_bow = vectorizer.transform(y_test)\n",
    "\n",
    "y_pred = clf.predict(test_bow)\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "\n",
    "test['target'] = pred\n",
    "\n",
    "test = test.drop(['keyword','location','text'], axis=1)\n",
    "\n",
    "test.to_csv('tf_MNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the F1 score improved slightly using TF-IDF method:\n",
    "![picture](https://drive.google.com/uc?id=1CJSKV0q40RvZcMXoU6qm7Z7Ihegd6Y1T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-Gram Method on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   65.12 % , Precision 0.566 Recall : 0.787 F1-Score :  0.659\n",
      "The confusion Matrix : \n",
      "[[1901 1556]\n",
      " [ 551 2033]]\n",
      "Time used : 147.340 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   78.27 % , Precision 0.741 Recall : 0.756 F1-Score :  0.748\n",
      "The confusion Matrix : \n",
      "[[2775  682]\n",
      " [ 631 1953]]\n",
      "Time used : 172.228 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   73.10 % , Precision 0.936 Recall : 0.398 F1-Score :  0.559\n",
      "The confusion Matrix : \n",
      "[[3387   70]\n",
      " [1555 1029]]\n",
      "Time used : 257.327 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "LogisticRegression Accuracy  :   79.49 % , Precision 0.836 Recall : 0.647 F1-Score :  0.730\n",
      "The confusion Matrix : \n",
      "[[3130  327]\n",
      " [ 912 1672]]\n",
      "Time used : 312.777 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ng = CountVectorizer(ngram_range=[1,3])\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "x_train_ng = vectorizer_ng.fit_transform(x_train)\n",
    "\n",
    "# Transform X_test\n",
    "x_test_ng = vectorizer_ng.transform(x_test)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,x_train_ng.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When these predicted values were submitted on Kaggle, it gave a score of 0.7965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining CountVectorizer() and TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=\"english\", min_df=3)\n",
    "tf_transformer = TfidfVectorizer(use_idf=True)\n",
    "combined_features = FeatureUnion([(\"counts\", count_vectorizer), (\"tfidf\", tf_transformer)]).fit_transform(x_train)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(combined_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   61.79 % , Precision 0.537 Recall : 0.774 F1-Score :  0.634\n",
      "The confusion Matrix : \n",
      "[[1732 1725]\n",
      " [ 583 2001]]\n",
      "Time used : 30.231 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   79.27 % , Precision 0.782 Recall : 0.714 F1-Score :  0.747\n",
      "The confusion Matrix : \n",
      "[[2944  513]\n",
      " [ 739 1845]]\n",
      "Time used : 8.382 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   80.28 % , Precision 0.840 Recall : 0.666 F1-Score :  0.743\n",
      "The confusion Matrix : \n",
      "[[3130  327]\n",
      " [ 864 1720]]\n",
      "Time used : 16.538 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "LogisticRegression Accuracy  :   79.47 % , Precision 0.798 Recall : 0.697 F1-Score :  0.744\n",
      "The confusion Matrix : \n",
      "[[3001  456]\n",
      " [ 784 1800]]\n",
      "Time used : 49.932 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,combined_features.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(combined_features.toarray(),y_train)\n",
    "\n",
    "test = t1\n",
    "y_test = test['text']\n",
    "y_test = y_test.apply(tokenize)\n",
    "y_test = y_test.apply(remove_words)\n",
    "y_test = y_test.apply(lemmatize)\n",
    "\n",
    "test_bow = FeatureUnion([(\"counts\", count_vectorizer), (\"tfidf\", tf_transformer)]).transform(y_test)\n",
    "\n",
    "y_pred = clf.predict(test_bow)\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "\n",
    "test['target'] = pred\n",
    "\n",
    "test = test.drop(['keyword','location','text'], axis=1)\n",
    "\n",
    "test.to_csv('cv_tf_MNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the F1 score has improved to 80.26%\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1cSdLFZQzzOwmqpMdNfXqtGP2Ke-pLdKg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy  :   65.77 % , Precision 0.576 Recall : 0.756 F1-Score :  0.654\n",
      "The confusion Matrix : \n",
      "[[2020 1437]\n",
      " [ 631 1953]]\n",
      "Time used : 262.687 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Multinomial Naive Bayes Accuracy  :   79.06 % , Precision 0.758 Recall : 0.749 F1-Score :  0.754\n",
      "The confusion Matrix : \n",
      "[[2840  617]\n",
      " [ 648 1936]]\n",
      "Time used : 52.544 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "Bernoulli Naive Bayes Accuracy  :   77.88 % , Precision 0.912 Recall : 0.534 F1-Score :  0.674\n",
      "The confusion Matrix : \n",
      "[[3324  133]\n",
      " [1203 1381]]\n",
      "Time used : 174.226 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n",
      "LogisticRegression Accuracy  :   79.85 % , Precision 0.821 Recall : 0.676 F1-Score :  0.742\n",
      "The confusion Matrix : \n",
      "[[3077  380]\n",
      " [ 837 1747]]\n",
      "Time used : 302.130 seconds\n",
      " *-----------------------------------------------------------------------------------------------------*\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=\"english\", min_df=3)\n",
    "tf_transformer = TfidfVectorizer(use_idf=True)\n",
    "ngram = CountVectorizer(ngram_range=[1,3])\n",
    "\n",
    "combined_features = FeatureUnion([(\"counts\", count_vectorizer), (\"tfidf\", tf_transformer), (\"ngram\", ngram)]).fit_transform(x_train)\n",
    "classifier.fit(combined_features, y_train)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "  #Cross validation prediction, and we measure fitting time \n",
    "  start = time.time()\n",
    "  preds = cross_val_predict(clf,combined_features.toarray(),y_train,cv=5)\n",
    "  end = time.time()\n",
    "  #Metrics\n",
    "  acc = accuracy_score(y_train,preds)\n",
    "  precision = precision_score(y_train,preds)\n",
    "  recall = recall_score(y_train,preds)\n",
    "  f1 = f1_score(y_train,preds)\n",
    "  cm = confusion_matrix(y_train,preds)\n",
    "  #Printing results\n",
    "  print (name, 'Accuracy  :  ', \"%.2f\" %(acc*100),'%', ', Precision',\"%.3f\" %precision, 'Recall :' , \"%.3f\" %recall ,'F1-Score : ',\"%.3f\" %f1)\n",
    "  print('The confusion Matrix : ' )\n",
    "  print(cm)\n",
    "  #Now we check how long did it take\n",
    "  print('Time used :', \"%.3f\" %(end - start), 'seconds')\n",
    "  print(' *-----------------------------------------------------------------------------------------------------*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction gives an F1 score of 0.79243."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(combined_features.toarray(),y_train)\n",
    "\n",
    "test = t1\n",
    "y_test = test['text']\n",
    "y_test = y_test.apply(tokenize)\n",
    "y_test = y_test.apply(remove_words)\n",
    "y_test = y_test.apply(lemmatize)\n",
    "\n",
    "test_bow = FeatureUnion([(\"counts\", count_vectorizer), (\"tfidf\", tf_transformer), (\"ngram\", ngram)]).transform(y_test)\n",
    "\n",
    "y_pred = clf.predict(test_bow)\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "\n",
    "test['target'] = pred\n",
    "\n",
    "test = test.drop(['keyword','location','text'], axis=1)\n",
    "\n",
    "test.to_csv('cv_tf_ng_LR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction gives an F1 score of 0.79652"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the top scores obtained are shown in the screenshot below:\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=180PknEPk91NDto9hPqhykyT2xQ2wdI89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conclusions can be made:\n",
    "- The F1 score of the model can be increased when transformations are ensembled together\n",
    "    * In this case, the combination of CounVectorizer() and TfidfVectorizer() functions produced the highest F1 score\n",
    "- Other models like BERT can be implemented to identify any improvements in the analysis\n",
    "- Data can be analysed from a different perspective such as - FAKE tweets usually have:\n",
    "    * a higher count of NOUNS compared to the average number of NOUNS for each tweet in the dataset\n",
    "    * longer sentences compared to REAL tweets\n",
    "\n",
    "Hence, as a future work, calculate the average number of NOUNS within a dataset, and compare it to the number of NOUNS present in a FAKE tweet. Similarly, calculate the length of FAKE tweets vs REAL tweets, and observe the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
